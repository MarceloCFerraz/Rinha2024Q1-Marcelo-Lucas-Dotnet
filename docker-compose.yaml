version: "3.5"

services:
    db:
        image: postgres:16.2-bullseye
        hostname: db
        # command: "postgres -c shared_buffers=256MB -c fsync=off -c full_page_writes=off -c max_connections=1000"
        ports:
            - "5432:5432"
        volumes:
            - ./create_db.sql:/docker-entrypoint-initdb.d/create_db.sql
        deploy:
            resources:
                limits:
                    # Note que a soma de todos os limites dos serviços
                    # aqui declarados é de 1.5 unidades de CPU e 550MB
                    # de memória. A distribuição feita aqui é apenas
                    # um exemplo – distribua como quiser.
                    cpus: "0.13"
                    memory: "140MB"
        environment:
            - POSTGRES_PASSWORD=123
            - POSTGRES_USER=admin
            - POSTGRES_DB=rinha
    api01: &api
        # Lembre-se de que seu serviço HTTP deve estar hospedado num repositório
        # publicamente acessível! Ex.: hub.docker.com
        image: marcelocferraz/rinha2024q1-marcelo-lucas-dotnet:latest
        hostname: api01
        ports:
            - "8081:8081"
        environment:
            - API_PORT=8081
            - DB_HOSTNAME=db
            - DB_NAME=rinha
            - DB_USER=admin
            - DB_PASS=123
        # Não é necessário expor qualquer porta além da porta do load balancer,
        # mas é comum as pessoas o fazerem para testarem suas APIs e conectarem
        # ao banco de dados na fase de desenvolvimento.
        depends_on:
            - db
        deploy:
            resources:
                limits:
                    cpus: "0.6"
                    memory: "200MB"
    api02:
        # Essa sintaxe reusa o que foi declarado em 'api01'.
        <<: *api
        hostname: api02
        ports:
            - "8082:8082"
        environment:
            - API_PORT=8082
            - DB_HOSTNAME=db
            - DB_NAME=rinha
            - DB_USER=admin
            - DB_PASS=123
        depends_on:
            - api01
    load_balancer:
        image: nginx:latest
        volumes:
            - ./nginx.conf:/etc/nginx/nginx.conf:ro
        depends_on:
            - api01
            - api02
        ports:
            # Obrigatório expor/usar a porta 9999 no load balancer!
            - "9999:9999"
        deploy:
            resources:
                limits:
                    cpus: "0.17"
                    memory: "10MB"

# O uso do modo `bridge` deve ser adequado à carga que será usada no teste.
# A edição anterior se beneficiou do modo host pois o volume de requisições
# era relativamente alto e a virtualização da rede se tornou um gargalo, mas
# este modo é mais complexo de ser configurado. Fique à vontade para usar o
# modo que quiser desde que não conflite com portas trivialmente usadas em um
# SO.
networks:
    default:
        driver: bridge
        name: rinha-nginx-2024q1
