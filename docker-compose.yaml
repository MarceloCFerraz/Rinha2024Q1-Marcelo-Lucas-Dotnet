version: "3.5"

services:
    db:
        image: postgres:16.2-bullseye
        hostname: db
        # command: "postgres -c shared_buffers=256MB -c fsync=off -c full_page_writes=off  -c max_connections=1000"
        command: "postgres -c shared_buffers=256MB -c fsync=off -c full_page_writes=off"
        ports:
            - "5432:5432"
        volumes:
            - ./DbSchema/create_db.sql:/docker-entrypoint-initdb.d/create_db.sql
        # Note que a soma de todos os limites dos serviços
        # aqui declarados é de 1.5 unidades de CPU e 550MB
        # de memória. A distribuição feita aqui é apenas
        # um exemplo – distribua como quiser.
        deploy:
            resources:
                limits:
                    cpus: "0.4"
                    memory: "220MB"
        environment:
            - POSTGRES_PASSWORD=mystrongpassword
            - POSTGRES_USER=admin
            - POSTGRES_DB=rinha

    api01: &api
        # Lembre-se de que seu serviço HTTP deve estar hospedado num repositório
        # publicamente acessível! Ex.: hub.docker.com
        image: rinha2024q1-marcelo-lucas-dotnet:latest
        # image: marcelocferraz/rinha2024q1-marcelo-lucas-dotnet:latest
        hostname: api01
        ports:
            - "8081:8081"
        environment:
            - API_PORT=8081
            - DB_PORT=5432
            - DB_HOSTNAME=db
            - DB_NAME=rinha
            - DB_USER=admin
            - DB_PASS=mystrongpassword
        # Não é necessário expor qualquer porta além da porta do load balancer,
        # mas é comum as pessoas o fazerem para testarem suas APIs e conectarem
        # ao banco de dados na fase de desenvolvimento.
        depends_on:
            - db
        deploy:
            resources:
                limits:
                    cpus: "0.4"
                    memory: "115MB"
        #         limits:
        #             cpus: "0.6"
        #             memory: "200MB"
    api02:
        # Essa sintaxe reusa o que foi declarado em 'api01'.
        <<: *api
        hostname: api02
        ports:
            - "8082:8082"
        environment:
            - API_PORT=8082
        depends_on:
            - api01

    load_balancer:
        image: nginx:latest
        volumes:
            - ./NginxConf/nginx.conf:/etc/nginx/nginx.conf:ro
        depends_on:
            - api01
            - api02
        ports:
            # Obrigatório expor/usar a porta 9999 no load balancer!
            - "9999:9999"
        deploy:
            resources:
                limits:
                    cpus: "0.3"
                    memory: "100MB"

# O uso do modo `bridge` deve ser adequado à carga que será usada no teste.
# A edição anterior se beneficiou do modo host pois o volume de requisições
# era relativamente alto e a virtualização da rede se tornou um gargalo, mas
# este modo é mais complexo de ser configurado. Fique à vontade para usar o
# modo que quiser desde que não conflite com portas trivialmente usadas em um
# SO.
networks:
    default:
        driver: bridge
        name: rinha-nginx-2024q1
